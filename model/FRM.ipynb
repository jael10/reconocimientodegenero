{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = glob('./data/female/*.jpg')\n",
    "mpath = glob('./data/male/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('El número de imagenes de Mujer en la carpeta es=',len(fpath))\n",
    "print('El número de imagenes de Hombres en la carpeta es=',len(mpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(fpath[0])\n",
    "img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "haar = cv2.CascadeClassifier('./haarcascade_frontalcatface.xml')\n",
    "gray = cv2.cvtColor(img_rgb,cv2.COLOR_BGR2GRAY)\n",
    "faces_list = haar.detectMultiScale(gray,1.5,5)\n",
    "print(faces_list)\n",
    "for x,y,w,h in faces_list:\n",
    "    cv2.rectangle(img_rgb,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    roi= img_rgb[y:y+h,x:x+w]\n",
    "    \n",
    "    plt.imshow(roi)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fpath)):\n",
    "    try:\n",
    "        img = cv2.imread(fpath[i])\n",
    "        img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img_rgb,cv2.COLOR_BGR2GRAY)\n",
    "        faces_list = haar.detectMultiScale(gray,1.5,5)\n",
    "        for x,y,w,h in faces_list:\n",
    "            roi = img[y:y+h,x:x+w]\n",
    "            cv2.imwrite(f'./crop_data/female/female_{i}.jpg',roi)\n",
    "            print('Se recortaron todas las imagenes de mujeres')\n",
    "    except:\n",
    "        print('El proceso de recorte tuvo un error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mpath)):\n",
    "    try:\n",
    "        img = cv2.imread(mpath[i])\n",
    "        img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img_rgb,cv2.COLOR_BGR2GRAY)\n",
    "        faces_list = haar.detectMultiScale(gray,1.5,5)\n",
    "        for x,y,w,h in faces_list:\n",
    "            roi = img[y:y+h,x:x+w]\n",
    "            cv2.imwrite(f'./crop_data/male/male_{i}.jpg',roi)\n",
    "            print('Se recortaron todas las imagenes de hombres')\n",
    "    except:\n",
    "        print('El proceso de recorte tuvo un error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structuring(path):\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        size = gray.shape[0]\n",
    "        if size >= 100:\n",
    "            gray_resize = cv2.resize(gray,(100,100),cv2.INTER_AREA)\n",
    "        else:\n",
    "            gray_resize = cv2.resize(gray,(100,100),cv2.INTER_CUBIC)\n",
    "        flatten_image = gray_resize.flatten()\n",
    "        return flatten_image\n",
    "    \n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = glob('./crop_data/female/*.jpg')\n",
    "mpath = glob('./crop_data/male/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female = pd.DataFrame(fpath,columns=['filepath'])\n",
    "df_female['gender'] = 'female'\n",
    "\n",
    "df_male = pd.DataFrame(mpath,columns=['filepath'])\n",
    "df_male['gender'] = 'male'\n",
    "\n",
    "df = pd.concat((df_female,df_male),axis=0)\n",
    "\n",
    "df['dimension'] = df['filepath'].apply(get_size)\n",
    "\n",
    "df_filter = df.query('dimension > 60')\n",
    "df_filter.shape\n",
    "df_filter['data'] = df_filter['filepath'].apply(structuring)\n",
    "\n",
    "data = df_filter['data'].apply(pd.Series)\n",
    "data.columns = [f\"pixel_{i}\" for i in data.columns]\n",
    "\n",
    "data = data/255.0 \n",
    "data['gender'] = df_filter['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().sum()\n",
    "data.dropna(inplace=True)\n",
    "pickle.dump(data,open('./data/data_images_100_100.pickle',mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./data/data_images_100_100.pickle',mode='rb'))\n",
    "X = data.drop('gender',axis=1).values\n",
    "\n",
    "mean_face = X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mean_face.reshape((100,100)),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X - mean_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=None,whiten=True,svd_solver='auto')\n",
    "pca.fit(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_df = pd.DataFrame()\n",
    "exp_var_df['explained_var'] = pca.explained_variance_ratio_\n",
    "exp_var_df['cum_explained_var'] = exp_var_df['explained_var'].cumsum()\n",
    "exp_var_df['principal_components'] = np.arange(1,len(exp_var_df)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_df.set_index('principal_components',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_50 = PCA(n_components=50,whiten=True,svd_solver='auto')\n",
    "pca_data = pca_50.fit_transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['gender'].values\n",
    "np.savez('./data/data_pca_50_target',pca_data,y)\n",
    "pca_dict = {'pca':pca_50,'mean_face':mean_face}\n",
    "pickle.dump(pca_dict,open('../model/pca_dict.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data_inv = pca_50.inverse_transform(pca_data)\n",
    "eig_img = pca_data_inv[0,:].reshape((100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(eig_img,cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1001)\n",
    "pics = np.random.randint(0,4319,40)\n",
    "plt.figure(figsize=(15,8))\n",
    "for i,pic in enumerate(pics):\n",
    "    plt.subplot(4,10,i+1)\n",
    "    img = X[pic:pic+1].reshape(100,100)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.title('{}'.format(y[pic]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*20+'Valores propios de las imagenes'+\"=\"*20)\n",
    "plt.figure(figsize=(15,8))\n",
    "for i,pic in enumerate(pics):\n",
    "    plt.subplot(4,10,i+1)\n",
    "    img = pca_data_inv[pic:pic+1].reshape(100,100)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.title('{}'.format(y[pic]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/data_pca_50_target.npz')\n",
    "\n",
    "data.allow_pickle = True\n",
    "\n",
    "X = data['arr_0']\n",
    "y = data['arr_1']\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = SVC(probability=True)\n",
    "\n",
    "param_grid = {'C':[0.5,1,10,20,30,50],\n",
    "             'kernel':['rbf','poly'],\n",
    "             'gamma':[0.1,0.05,0.01,0.001,0.002,0.005],\n",
    "             'coef0':[0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = GridSearchCV(model_svc,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='accuracy',cv=3,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = model_grid.best_estimator_\n",
    "model_final.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_final.predict(x_test)\n",
    "\n",
    "cr = metrics.classification_report(y_test,y_pred,output_dict=True)\n",
    "\n",
    "metrics.roc_auc_score(np.where(y_test==\"male\",1,0),\n",
    "                      np.where(y_pred==\"male\",1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_final,open('../model/model_svm.pickle',mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar = cv2.CascadeClassifier('../model/haarcascade_frontalcatface.xml')\n",
    "model_svm =  pickle.load(open('../model/model_svm.pickle',mode='rb'))\n",
    "pca_models = pickle.load(open('../model/pca_dict.pickle',mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = pca_models['pca']\n",
    "mean_face_arr = pca_models['mean_face']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/getty_test.jpg')\n",
    "gray =  cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "faces = haar.detectMultiScale(gray,1.5,3)\n",
    "predictions = []\n",
    "for x,y,w,h in faces:\n",
    "    roi = gray[y:y+h,x:x+w]\n",
    "    roi = roi / 255.0\n",
    "    if roi.shape[1] > 100:\n",
    "        roi_resize = cv2.resize(roi,(100,100),cv2.INTER_AREA)\n",
    "    else:\n",
    "        roi_resize = cv2.resize(roi,(100,100),cv2.INTER_CUBIC)\n",
    "    roi_reshape = roi_resize.reshape(1,10000)\n",
    "    roi_mean = roi_reshape - mean_face_arr\n",
    "    eigen_image = model_pca.transform(roi_mean)\n",
    "    eig_img = model_pca.inverse_transform(eigen_image)\n",
    "    results = model_svm.predict(eigen_image)\n",
    "    prob_score = model_svm.predict_proba(eigen_image)\n",
    "    prob_score_max = prob_score.max()\n",
    "    text = \"%s : %d\"%(results[0],prob_score_max*100)\n",
    "    if results[0] == 'male':\n",
    "        color = (255,255,0)\n",
    "    else:\n",
    "        color = (255,0,255)\n",
    "        \n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "    cv2.rectangle(img,(x,y-40),(x+w,y),color,-1)\n",
    "    cv2.putText(img,text,(x,y),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),5)\n",
    "    output = {\n",
    "        'roi':roi,\n",
    "        'eig_img': eig_img,\n",
    "        'prediction_name':results[0],\n",
    "        'score':prob_score_max\n",
    "    }\n",
    "    \n",
    "    predictions.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    obj_gray = predictions[i]['roi']\n",
    "    obj_eig = predictions[i]['eig_img'].reshape(100,100)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(obj_gray,cmap='gray')\n",
    "    plt.title('Escala de grises en la imagen')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(obj_eig,cmap='gray')\n",
    "    plt.title('Valores propios de la imagen')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    print('Predicción del genero =',predictions[i]['prediction_name'])\n",
    "    print('Puntaje de la predicción = {:,.2f} %'.format(predictions[i]['score']*100))\n",
    "    \n",
    "    print('-'*100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
